---
layout: default
title: 3.4 Verbessern
parent: 3. Hauptteil
nav_order: 7
---
#  Verbessern (Improve) Phase

Die Improve-Phase ist der vierte Schritt in einem Six Sigma Projekt. In dieser Phase werden die in der [Analyze-Phase](./33_analysieren.md) identifizierten Hauptursachen fÃ¼r Prozessabweichungen adressiert und LÃ¶sungen entwickelt, um diese zu beheben. Ziel ist es, durch gezielte Verbesserungsmassnahmen die Prozessleistung zu optimieren und die identifizierten Probleme nachhaltig zu lÃ¶sen. Dies umfasst die Anwendung von KreativitÃ¤tstechniken, statistischen Methoden und Pilotprojekten, um die Wirksamkeit der vorgeschlagenen LÃ¶sungen zu testen und zu validieren.

Der Fokus dieser Phase liegt **nicht auf der Neuentwicklung der Applikation**, sondern auf der **Migration, Automatisierung und dem cloud-nativen Betrieb** eines bereits bestehenden LizenzÃ¼berwachungstools. Der funktionale Umfang der Anwendung wurde in einer vorherigen Semesterarbeit umgesetzt und bleibt im Rahmen dieser Arbeit unverÃ¤ndert.

Ziel der Improve-Phase ist es, die bestehende Anwendung so weiterzuentwickeln, dass sie reproduzierbar bereitgestellt, automatisiert betrieben und nachhaltig gewartet werden kann â€“ im Sinne moderner DevOps- und Cloud-Native-Core-Prinzipien.

![Verbessern](../../ressources/images/verbessern.png)

[Quelle](../Quellverzeichnis/index.md#improve-phase)

## Architekturgrundlage des LizenzÃ¼berwachungstools

Das LizenzÃ¼berwachungstool basiert auf einem **Microservice-Architekturstil (MSVC)** und nutzt **Python mit Flask** zur Umsetzung der einzelnen Services. Diese Architektur bildet die fachliche und technische Grundlage fÃ¼r die nachfolgenden Verbesserungsmassnahmen.

### Microservice-Architektur (MSVC) und Flask API

Bei einer Microservice-Architektur wird eine Anwendung nicht als monolithisches System umgesetzt, sondern in mehrere kleine, unabhÃ¤ngige Dienste aufgeteilt. Jeder dieser Dienste Ã¼bernimmt eine klar abgegrenzte fachliche Aufgabe und kann unabhÃ¤ngig entwickelt, betrieben und skaliert werden.

Im vorliegenden Projekt fungieren die Flask-Services als **REST-basierte APIs**, welche unter anderem folgende Aufgaben Ã¼bernehmen:
- Abfrage von Lizenzinformationen Ã¼ber die Microsoft Graph API
- Verarbeitung und Aufbereitung der Lizenzdaten
- Bereitstellung von Schnittstellen fÃ¼r weitere Systeme oder Automatisierungen

Durch den Einsatz von Flask als leichtgewichtigem Framework bleiben die Services bewusst schlank und stateless. Dies erleichtert nicht nur die Containerisierung, sondern ist auch eine zentrale Voraussetzung fÃ¼r den spÃ¤teren Betrieb in einer Cloud-Native-Umgebung.

Diese Architekturentscheidung unterstÃ¼tzt die in der Analyze-Phase identifizierten Verbesserungsziele direkt: geringere Kopplung, bessere Wartbarkeit und gezielte Skalierbarkeit einzelner Komponenten.

---

## Cloud-Native Core (CNC) als Zielarchitektur

Um die bestehenden Microservices effizient, stabil und automatisiert betreiben zu kÃ¶nnen, wird das LizenzÃ¼berwachungstool in eine **Cloud-Native-Core-Architektur (CNC)** Ã¼berfÃ¼hrt. CNC beschreibt dabei keinen einzelnen Technologie-Stack, sondern ein Architekturprinzip.

Zentrale Merkmale dieser Architektur sind:
- Containerisierte Anwendungen
- Deklarative Infrastruktur
- Automatisierte Deployments
- Skalierbarkeit und Self-Healing
- Klare Trennung von Code, Konfiguration und Laufzeit

Durch die Umsetzung dieser Prinzipien wird sichergestellt, dass die Anwendung reproduzierbar betrieben, einfach erweitert und zuverlÃ¤ssig Ã¼berwacht werden kann.

---

## Minikube als Kubernetes-Laufzeitumgebung

FÃ¼r die praktische Umsetzung der Cloud-Native-Core-Architektur wird **Minikube** als Kubernetes-Umgebung eingesetzt. Minikube ermÃ¶glicht den Betrieb eines vollstÃ¤ndigen Kubernetes-Clusters in einer lokalen Umgebung und eignet sich damit ideal fÃ¼r Entwicklungs-, Test- und Evaluationszwecke.

Der Einsatz von Minikube bietet mehrere Vorteile im Kontext dieser Semesterarbeit:
- Realistisches Kubernetes-Verhalten ohne Cloud-AbhÃ¤ngigkeit
- Volle Kontrolle Ã¼ber Infrastruktur und Konfiguration
- KonformitÃ¤t mit den Datenschutzanforderungen (DSG)
- Nahtlose Integration in CI/CD-Pipelines

Durch Minikube kann die Zielarchitektur praxisnah umgesetzt werden, ohne die im Analyse-Teil identifizierten Risiken eines Cloud-Deployments einzugehen. Gleichzeitig bleibt die Architektur so gestaltet, dass ein spÃ¤terer Wechsel auf eine Cloud-Plattform grundsÃ¤tzlich mÃ¶glich wÃ¤re.

---

## Evaluation und Festlegung der Infrastruktur

Zu Beginn der Improve-Phase wurde die in der Analyze-Phase begonnene Infrastruktur-Evaluation konkretisiert. Dabei wurden sowohl **Cloud-basierte LÃ¶sungen** als auch eine **lokale Kubernetes-Umgebung** betrachtet. Entscheidende Bewertungskriterien waren unter anderem Datenschutz, Kontrolle Ã¼ber sensible Lizenzdaten, technische KomplexitÃ¤t sowie Kosten- und Betriebsaspekte.

Das Ergebnis dieser Evaluation war die bewusste Entscheidung fÃ¼r eine **lokale Kubernetes-Umgebung auf Basis von Minikube**. Diese LÃ¶sung ermÃ¶glicht ein realistisches Cloud-Native-Setup, ohne AbhÃ¤ngigkeiten von externen Cloud-Anbietern einzugehen. Gleichzeitig bleibt die Architektur so gestaltet, dass ein spÃ¤terer Wechsel in eine Cloud-Umgebung grundsÃ¤tzlich mÃ¶glich wÃ¤re.

| **Kriterium**        | **Gewicht** | **Azure**   | **AWS**     | **Lokal**   |
| -------------------- | ----------- | ----------- | ----------- | ----------- |
| Datenschutz / DSG    | **35%**     | Mittel (6)  | Niedrig (4) | â­ Hoch (9)  |
| Security             | **25%**     | Mittel (7)  | Mittel (7)  | â­ Hoch (9)  |
| Kosten               | 10%         | Mittel (6)  | Niedrig (5) | Mittel (6)  |
| Scalability          | 10%         | Hoch (9)    | Hoch (10)   | Niedrig (4) |
| Operational Control  | 10%         | Niedrig (5) | Niedrig (5) | â­ Hoch (9)  |
| Integration MS Graph | 10%         | Hoch (9)    | Mittel (7)  | Niedrig (4) |
_Gewichtete Entscheidungsmatrix, mehr details zur Evaluation unter [Vergleich der Deployment-Optionen](./33_analyze#vergleich-der-deployment-optionen)_

**Gesamtpunktzahl (0â€“10):**

- Azure: **6.75**
- AWS: **5.85**
- â­ **Lokal: 7.70**

Mit dieser Entscheidung wurde eine stabile und datenschutzkonforme Grundlage geschaffen, auf der alle weiteren Verbesserungen aufbauen.

---

## Weiterentwicklung zur Cloud-Native-Core-Architektur

Basierend auf der gewÃ¤hlten Zielinfrastruktur wurde das bestehende LizenzÃ¼berwachungstool konsequent in Richtung einer **Cloud-Native-Core-Architektur** weiterentwickelt. Dabei standen nicht einzelne Technologien im Vordergrund, sondern zentrale Architektur- und Betriebsprinzipien.

Umgesetzte Kernprinzipien waren unter anderem:

- Containerisierung der bestehenden Anwendung
- Trennung von Anwendungscode, Konfiguration und Infrastruktur
- Deklarative Beschreibung des gewÃ¼nschten Systemzustands
- Stateless-Betrieb der Applikation

Die Anwendung wurde als Container-Image bereitgestellt, ohne die fachliche Logik zu verÃ¤ndern. Durch diese Entkopplung ist die Applikation unabhÃ¤ngig von der Laufzeitumgebung und eignet sich fÃ¼r automatisierte Deployments und Skalierung innerhalb von Kubernetes.

![aufbau](../../ressources/images/zielarchitektur.png)
_Zielarchitektur_

---

## Aufbau einer CI/CD-Pipeline (Build & Artefakt-Erstellung)

Ein zentrales Ziel der Improve-Phase war die **Reduktion manueller Schritte** im Build- und Bereitstellungsprozess. Dazu wurde eine CI-Pipeline aufgebaut, welche Ã„nderungen am Quellcode automatisch verarbeitet.

Die Pipeline Ã¼bernimmt unter anderem:

- Build der Applikation
- Erstellung eines versionierten Container-Images
- Bereitstellung des Artefakts fÃ¼r das Deployment

Dadurch ist jeder Build eindeutig einer Code-Version zugeordnet und reproduzierbar. Fehlerquellen durch manuelle Builds oder inkonsistente Artefakte konnten so eliminiert werden.

![Pipeline Summary](../../ressources/images/ci1.png)
_Pipeline summary_

![Ci-Build](../../ressources/images/ci2.png)
_CI-Build der App_

![CI Build DH Artefact](../../ressources/images/ci3.png)
_CI Build des Dockerhub-Artefakts_

Diese Pipeline bildet die technische Grundlage fÃ¼r den nachfolgenden GitOps-basierten Deployment-Ansatz.

---

## EinfÃ¼hrung eines GitOps-Ansatzes mit Argo CD

FÃ¼r das Deployment der Anwendung wurde ein **GitOps-Ansatz** umgesetzt. Dabei dient das Git-Repository als Single Source of Truth fÃ¼r den gewÃ¼nschten Systemzustand.  
Als zentrales Werkzeug wurde **Argo CD** eingesetzt.

Die Struktur folgt dem **App-of-Apps-Pattern**, bei dem eine zentrale Bootstrap-Applikation weitere Applikationen verwaltet, darunter:

- Argo CD Core-Komponenten
- Sealed Secrets Controller
- LicenseMonitor Applikation

Diese Struktur ermÃ¶glicht eine klare Trennung von Verantwortlichkeiten und eine saubere Steuerung von AbhÃ¤ngigkeiten.

![Argo CD UI Overview](../../ressources/images/argocd_ui_overview.png)
_ArgoCD UI Overview_

Durch GitOps wird sichergestellt, dass jede Ã„nderung nachvollziehbar versioniert ist und automatisch in die Kubernetes-Umgebung synchronisiert wird.

---

## Sicheres Secrets Management mit Sealed Secrets

Ein wesentlicher Schwerpunkt der Improve-Phase lag auf der **Sicherstellung von Datenschutz und Betriebssicherheit**. Sensible Daten wie Zertifikate, Tenant-Profile und Authentifizierungsparameter dÃ¼rfen weder im Klartext im Repository abgelegt noch manuell in Pods konfiguriert werden.

Daher wurde das **Sealed-Secrets-Konzept** eingefÃ¼hrt:

- Secrets werden lokal erstellt
- clientseitig verschlÃ¼sselt (`kubeseal`)
- als SealedSecrets im Git-Repository versioniert
- ausschlieÃŸlich im Cluster entschlÃ¼sselt

```text
infra/ 
â””â”€â”€ k8s/     
	â””â”€â”€ apps/         
		â””â”€â”€ licensetool/             
			â””â”€â”€ overlays/                 
				â””â”€â”€ dev/                     
					â””â”€â”€ sealed-secret.yaml
```
_Dateistruktur der Sealed Secrets_

```output
PS C:\Users\miguel.schneider> kubeseal --controller-name "sealed-secrets" --controller-namespace "kube-system" --fetch-cert
-----BEGIN CERTIFICATE-----
MIIEzDCCArSgAwIBAgIQaW/IbK02PNctcQpjqggjnzANBgkqhkiG9w0BAQsFADAA
MB4XDTI2MDEyMjIzMzE1OFoXDTM2MDEyMDIzMzE1OFowADCCAiIwDQYJKoZIhvcN...
```
_Teiloutput CLI, des Sealed-Secrets _

Damit ist sichergestellt, dass zu keinem Zeitpunkt Klartext-Secrets im Repository oder in der CI/CD-Pipeline vorhanden sind.

---

## Technische Stabilisierung der Kubernetes-Integration

WÃ¤hrend der Umsetzung traten mehrere Kubernetes-spezifische Probleme auf, insbesondere im Umgang mit Secrets, Mount-Pfaden und Namenskonventionen.  
Zertifikate und Konfigurationsprofile waren ursprÃ¼nglich auf lokale Dateisysteme ausgelegt und mussten fÃ¼r einen zustandslosen Pod-Betrieb angepasst werden.

Die folgenden Verbesserungen wurden umgesetzt:
- Migration aller Zertifikate und Profile in Kubernetes Secrets
- Einheitliche Mount-Pfade innerhalb der Container
- Trennung von tenant-spezifischen und serviceweiten Zertifikaten
- EinfÃ¼hrung verbindlicher Namenskonventionen fÃ¼r Kubernetes-Ressourcen

Die Wirksamkeit dieser Massnahmen wurde iterativ Ã¼berprÃ¼ft durch:
- Analyse von Pod-Logs
- Validierung gemounteter Dateien
- Funktionstests der Microsoft- und SharePoint-Integrationen

ğŸ“Œ **Hier CLI-Ausgabe einfÃ¼gen:**  
`kubectl exec â€¦ ls /app/certs`  
`kubectl logs licensetool-pod`

Nach diesen Anpassungen lief die Applikation stabil mit mehreren Replikas.

---

## Fehleranalyse und Troubleshooting (Argo CD Repo Server)

WÃ¤hrend der GitOps-EinfÃ¼hrung trat ein kritischer Fehler auf:

> _Failed to load target state: connection refused (argocd-repo-server)_

Die Ursache lag in einem inkonsistenten Zustand des Argo CD Repo Servers. Ein gezielter Neustart des Deployments stellte die Kommunikation wieder her.

ğŸ“Œ **Hier CLI-Ausgabe einfÃ¼gen:**  
`kubectl -n argocd get pods`  
`kubectl -n argocd rollout restart deploy/argocd-repo-server`

ğŸ“Œ **Hier Screenshot einfÃ¼gen:**  
_Argo CD â€“ Application Status: Healthy / Synced_

Dieser Schritt wurde dokumentiert und als Bestandteil des Troubleshooting-Wissens festgehalten.

---

## Ergebnis und Zielerreichung der Improve-Phase

Durch die umgesetzten Massnahmen konnten alle definierten Ziele erreicht werden:

- Die Infrastruktur wurde evaluiert und nachvollziehbar festgelegt
- Build- und Deployment-Prozesse sind automatisiert
- Die Anwendung folgt Cloud-Native-Core-Prinzipien
- Datenschutz und Betriebssicherheit sind Kubernetes-konform umgesetzt
- Die Umgebung ist reproduzierbar und stabil betreibbar

---

## Fazit der Improve-Phase

Die Improve-Phase fÃ¼hrte zu einer nachhaltigen technischen Stabilisierung des LizenzÃ¼berwachungstools.  
Durch die Kombination aus **CI/CD**, **GitOps**, **Sealed Secrets** und klarer Architektur wurde eine LÃ¶sung geschaffen, die nicht nur funktional, sondern auch betrieblich und organisatorisch Ã¼berzeugt.

Die Anwendung kann nach einem vollstÃ¤ndigen Re-Deploy des Clusters ohne manuelle Eingriffe wiederhergestellt werden und bildet eine solide Grundlage fÃ¼r zukÃ¼nftige Erweiterungen oder einen mÃ¶glichen Cloud-Betrieb.